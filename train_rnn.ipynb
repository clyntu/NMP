{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"Main script used for training.\"\"\"\n",
    "from tensorflow.keras.callbacks import TensorBoard, CSVLogger\n",
    "from tensorflow.keras.models import load_model\n",
    "import keras.metrics\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import os\n",
    "from nmp import model as mod\n",
    "from nmp import dataset, ev_metrics\n",
    "from nmp.dataset import pyplot_piano_roll\n",
    "from nmp import plotter\n",
    "from pathlib import Path\n",
    "import time\n",
    "import math\n",
    "import pypianoroll\n",
    "from pypianoroll import Multitrack, Track\n",
    "import numpy as np\n",
    "import random\n",
    "import copy\n",
    "\n",
    "# P = Path(__file__).parent.absolute()\n",
    "P = Path(os.path.abspath(''))  # Compatible with Jupyter Notebook\n",
    "P2 = Path('S:\\datasets')  # Dataset path\n",
    "\n",
    "PLOTS = P / 'plots'  # Plots path\n",
    "FS = 24  # Sampling frequency. 10 Hz = 100 ms\n",
    "Q = 0  # Quantize?\n",
    "st = 1  # Past timesteps\n",
    "num_ts = 1  # Predicted timesteps\n",
    "DOWN = 12  # Downsampling factor\n",
    "# D = \"data/Piano-midi.de\"  # Dataset\n",
    "D = \"data/Nottingham\"  # Dataset\n",
    "# D = \"data/MuseData\"  # Dataset\n",
    "\n",
    "LOW_LIM = 33  # A1\n",
    "HIGH_LIM = 97  # C7\n",
    "\n",
    "# LOW_LIM = 36  # C2\n",
    "# HIGH_LIM = 85  # C6\n",
    "\n",
    "# Complete 88-key keyboard\n",
    "# LOW_LIM = 21  # A0\n",
    "# HIGH_LIM = 109  # C8\n",
    "\n",
    "NUM_NOTES = HIGH_LIM - LOW_LIM\n",
    "CROP = [LOW_LIM, HIGH_LIM]  # Crop plots\n",
    "\n",
    "LOAD = 0\n",
    "TRANS = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate list of MIDI files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_list = [x for x in os.listdir(P / D / 'train') if x.endswith('.mid')]\n",
    "validation_list = [x for x in os.listdir(P / D / 'valid') if x.endswith('.mid')]\n",
    "test_list = [x for x in os.listdir(P / D / 'test') if x.endswith('.mid')]\n",
    "\n",
    "print(\"\\nTrain list:  \", train_list)\n",
    "print(\"\\nValidation list:  \", validation_list)\n",
    "print(\"\\nTest list:  \", test_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate data from lists\n",
    "Training, validation and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "train = dataset.Dataset(train_list, P / D / 'train',  fs=FS, bl=0, quant=Q)\n",
    "validation = dataset.Dataset(validation_list, P / D / 'valid',  fs=FS, bl=0, quant=Q)\n",
    "test = dataset.Dataset(test_list, P / D / 'test',  fs=FS, bl=0, quant=Q)\n",
    "\n",
    "train.build_rnn_dataset(\"training\", down=DOWN, low_lim=LOW_LIM, high_lim=HIGH_LIM)\n",
    "validation.build_rnn_dataset(\"validation\", down=DOWN, low_lim=LOW_LIM, high_lim=HIGH_LIM)\n",
    "test.build_rnn_dataset(\"test\", down=DOWN, low_lim=LOW_LIM, high_lim=HIGH_LIM)\n",
    "\n",
    "end = time.time()\n",
    "print(\"Done\")\n",
    "print(\"Loading time: %.2f\" % (end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train.dataset[0].shape)\n",
    "print(train.dataset[1].shape)\n",
    "print(validation.dataset[0].shape)\n",
    "print(validation.dataset[1].shape)\n",
    "print(test.dataset[0].shape)\n",
    "print(test.dataset[1].shape)\n",
    "\n",
    "pyplot_piano_roll(test.dataset[1][:, :NUM_NOTES], cmap=\"Oranges\",\n",
    "                  low_lim=LOW_LIM, high_lim=HIGH_LIM)\n",
    "plt.title(\"Test target\")\n",
    "# plt.ylim(CROP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_length = 100\n",
    "import tensorflow as tf\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((train.dataset[0]))\n",
    "train_sequences = train_dataset.batch(seq_length+1, drop_remainder=True)\n",
    "\n",
    "valid_dataset = tf.data.Dataset.from_tensor_slices((validation.dataset[0]))\n",
    "valid_sequences = valid_dataset.batch(seq_length+1, drop_remainder=True)\n",
    "\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((test.dataset[0]))\n",
    "test_sequences = test_dataset.batch(seq_length+1, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_input_target(chunk):\n",
    "    input_text = chunk[:-1]\n",
    "    target_text = chunk[1:]\n",
    "    return input_text, target_text\n",
    "\n",
    "def split_input_target_base(chunk):\n",
    "    input_text = chunk[:-1]\n",
    "    target_text = chunk[:-1]\n",
    "    return input_text, target_text\n",
    "\n",
    "train_data = train_sequences.map(split_input_target)\n",
    "valid_data = valid_sequences.map(split_input_target)\n",
    "test_data = test_sequences.map(split_input_target)\n",
    "baseline_data = test_sequences.map(split_input_target_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch size\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "# Buffer size to shuffle the dataset\n",
    "# (TF data is designed to work with possibly infinite sequences,\n",
    "# so it doesn't attempt to shuffle the entire sequence in memory. Instead,\n",
    "# it maintains a buffer in which it shuffles elements).\n",
    "BUFFER_SIZE = 10000\n",
    "\n",
    "train_data = train_data.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n",
    "valid_data = valid_data.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n",
    "test_data = test_data.batch(1, drop_remainder=True)\n",
    "baseline_data = baseline_data.batch(1, drop_remainder=True)\n",
    "print(train_data)\n",
    "print(valid_data)\n",
    "print(test_data)\n",
    "print(baseline_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Piano rolls of training dataset\n",
    "Input and output piano rolls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.rcParams[\"figure.figsize\"] = (20, 8)\n",
    "# pyplot_piano_roll(train.dataset[0][:, 0, :],\n",
    "#                   low_lim=LOW_LIM, high_lim=HIGH_LIM)\n",
    "# plt.title(\"Train data\")\n",
    "# plt.ylim(CROP)\n",
    "# pyplot_piano_roll(train.dataset[1][:, :NUM_NOTES], cmap=\"Oranges\",\n",
    "#                   low_lim=LOW_LIM, high_lim=HIGH_LIM)\n",
    "# plt.title(\"Train target\")\n",
    "# plt.ylim(CROP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras\n",
    "### Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BS = BATCH_SIZE  # Batch size\n",
    "import importlib\n",
    "importlib.reload(mod)\n",
    "importlib.reload(dataset)\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if LOAD:\n",
    "    model = load_model(filepath=model_path,\n",
    "                       custom_objects=None,\n",
    "                       compile=True)\n",
    "\n",
    "else:\n",
    "    model = mod.build_gru_model(NUM_NOTES, BS)\n",
    "    mod.compile_model(model, 'binary_crossentropy', 'adam',\n",
    "                      metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "now = datetime.now()\n",
    "\n",
    "# Save logs\n",
    "logger = TensorBoard(log_dir=P / 'logs' / now.strftime(\"%Y%m%d-%H%M%S\"),\n",
    "                     write_graph=True, update_freq='epoch')\n",
    "\n",
    "csv_logger = CSVLogger(P / 'logs' / (now.strftime(\"%Y%m%d-%H%M%S\") + '-' +\n",
    "                       str(st) + '-' + str(num_ts) + '.csv'),\n",
    "                       separator=',', append=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try the model\n",
    "Try the model before training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for input_example_batch, target_example_batch in train_data.take(1):\n",
    "#     example_batch_predictions = model(tf.cast(input_example_batch, tf.float32))\n",
    "#     print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory where the checkpoints will be saved\n",
    "checkpoint_dir = P / 'models/training_checkpoints'\n",
    "# Name of the checkpoint files\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
    "\n",
    "checkpoint_callback=tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_prefix,\n",
    "    save_weights_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit the model\n",
    "Define batch size ```BS``` and number of ```epochs```\n",
    "\n",
    "#### fit generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Fit generator the model.\n",
    "# BS = 64  # Batch size\n",
    "# epochs = 20\n",
    "# start = time.time()\n",
    "# size_train = math.ceil(train.dataset[0].shape[0] / BS)\n",
    "# spe_train = size_train\n",
    "# size_valid = math.ceil(validation.dataset[0].shape[0] / BS)\n",
    "# spe_valid = size_valid\n",
    "# print(\"Train dataset shape: \", train.dataset[0].shape, \"\\n\")\n",
    "# print(\"Train dataset target shape: \", train.dataset[1].shape, \"\\n\")\n",
    "\n",
    "# # Fit generator. Data should be shuffled before fitting.\n",
    "# history = model.fit(dataset.generate((train.dataset[0], train.dataset[1]), trans=1), epochs=epochs,\n",
    "#           steps_per_epoch=spe_train,\n",
    "#           validation_data=dataset.generate((validation.dataset[0], validation.dataset[1])),\n",
    "#           validation_steps=spe_valid,\n",
    "#           callbacks=[logger, csv_logger])\n",
    "\n",
    "# end = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model.\n",
    "BS = BATCH_SIZE  # Batch size\n",
    "epochs = 500\n",
    "start = time.time()\n",
    "\n",
    "# Normal fit. Auto-shuffles data.\n",
    "history = model.fit(train_data, validation_data=valid_data, epochs=epochs, shuffle=True,\n",
    "                    callbacks=[logger, csv_logger, checkpoint_callback])\n",
    "\n",
    "end = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"\\nTraining time: \", (end-start), \"\\n\")\n",
    "hist = pd.DataFrame(history.history)\n",
    "hist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot loss function of training and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(constrained_layout=True, figsize=(5, 4))\n",
    "plt.plot(hist['val_loss'], '-', lw=3, c='tab:orange', label='Validation', ms=8, alpha=0.8)\n",
    "plt.plot(hist['loss'], '-', lw=1, c='tab:red', label='Train', ms=8, alpha=0.8)\n",
    "plt.xlabel('Epoch')\n",
    "# plt.xticks(range(epochs))\n",
    "plt.legend()\n",
    "plt.title('Loss: Binary cross-entropy')\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "# plt.ylim([0.12, 0.16])\n",
    "fig.savefig(PLOTS / 'rnn.eps', fmt='eps')\n",
    "print(\"Training time: \", (end-start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save model to file\n",
    "Model can be loaded with:\n",
    "``` python\n",
    "load_model(filepath=str(folder_path), compile=True)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(str(P / 'models' / 'simpleRNN-nottingham') + '.h5', save_format='h5')\n",
    "# model.save(str(P / 'models' / 'lstm-z-de') + '.h5', save_format='h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Evaluation on train set:\")\n",
    "e_train = model.evaluate(train_data)\n",
    "\n",
    "print(\"\\nEvaluation on validation set:\")\n",
    "e_valid = model.evaluate(valid_data)\n",
    "\n",
    "# print(\"\\nEvaluation on test set:\")\n",
    "# e_test = model.evaluate(test_data)\n",
    "\n",
    "results = {out: e_train[i] for i, out in enumerate(model.metrics_names)}\n",
    "res = pd.DataFrame(list(results.items()), columns=['metric', 'train'])\n",
    "res = res.set_index('metric')\n",
    "\n",
    "results2 = {out: e_valid[i] for i, out in enumerate(model.metrics_names)}\n",
    "res2 = pd.DataFrame(list(results2.items()), columns=['metric', 'validation'])\n",
    "res2 = res2.set_index('metric')\n",
    "\n",
    "# results3 = {out: e_test[i] for i, out in enumerate(model.metrics_names)}\n",
    "# res3 = pd.DataFrame(list(results3.items()), columns=['metric', 'test'])\n",
    "# res3 = res3.set_index('metric')\n",
    "res3 = pd.DataFrame([])\n",
    "\n",
    "result = pd.concat([res, res2, res3], axis=1, sort=False)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make predictions\n",
    "Predictions from test dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Restore last checkpoint\n",
    "\n",
    "Build again the model and restore the checkpoint with weights to use a different batch size for test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = mod.build_gru_model(NUM_NOTES, 1)\n",
    "mod.compile_model(model, 'binary_crossentropy', 'adam',\n",
    "                  metrics=['accuracy'])\n",
    "model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
    "model.build(tf.TensorShape([1, None]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.reset_states()\n",
    "predauc = []\n",
    "baseauc = []\n",
    "\n",
    "merged_input = []\n",
    "merged_output = []\n",
    "merged_pred = []\n",
    "\n",
    "for input_batch, label_batch in test_data.take(-1):\n",
    "    predictions = model(tf.cast(input_batch, tf.float32))\n",
    "\n",
    "    # print(tf.squeeze(predictions, 0))\n",
    "    pred = np.array(tf.squeeze(predictions, 0))\n",
    "    predictions_bin = dataset.ranked_threshold(pred, steps=1, how_many=5)\n",
    "\n",
    "    inp = np.array(tf.squeeze(input_batch, 0))\n",
    "    out = np.array(tf.squeeze(label_batch, 0))\n",
    "\n",
    "#     pyplot_piano_roll(out,\n",
    "#                       cmap=\"Greens\", low_lim=LOW_LIM, high_lim=HIGH_LIM)\n",
    "#     plt.title(\"Target\")\n",
    "#     plt.savefig(PLOTS / \"roll1.png\")\n",
    "\n",
    "#     pyplot_piano_roll(pred,\n",
    "#                       cmap=\"Purples\", low_lim=LOW_LIM, high_lim=HIGH_LIM)\n",
    "#     plt.title(\"Predictions\")\n",
    "#     plt.savefig(PLOTS / \"roll.png\")\n",
    "\n",
    "#     pyplot_piano_roll(inp,\n",
    "#                   cmap=\"Blues\", low_lim=LOW_LIM, high_lim=HIGH_LIM)\n",
    "#     plt.title(\"Baseline (repetition of the input)\")\n",
    "#     plt.savefig(PLOTS / \"roll3.png\")\n",
    "\n",
    "    pred_auc = ev_metrics.compute_auc(out, pred, NUM_NOTES)\n",
    "    base_auc = ev_metrics.compute_auc(out, inp, NUM_NOTES)\n",
    "    predauc.append(np.mean(np.mean(pred_auc)))\n",
    "    baseauc.append(np.mean(np.mean(base_auc)))\n",
    "\n",
    "    \n",
    "    # Merged piano rolls to compute overall AUC.\n",
    "    merged_input.append(inp)\n",
    "    merged_output.append(out)\n",
    "    merged_pred.append(pred)\n",
    "\n",
    "merged_input = np.concatenate([x for x in merged_input])\n",
    "merged_output = np.concatenate([x for x in merged_output])\n",
    "merged_pred = np.concatenate([x for x in merged_pred])\n",
    "\n",
    "pred_auc_merged = ev_metrics.compute_auc(merged_output, merged_pred, NUM_NOTES)\n",
    "base_auc_merged = ev_metrics.compute_auc(merged_output, merged_input, NUM_NOTES)\n",
    "\n",
    "print(\"Pred AUC-ROC (mean of subsets): \", np.mean(predauc))\n",
    "print(\"Base AUC-ROC:(mean of subsets): \", np.mean(baseauc))\n",
    "\n",
    "print(\"Pred AUC-ROC (global): \", np.mean(np.mean((pred_auc_merged))))\n",
    "print(\"Base AUC-ROC (global): \", np.mean(np.mean((base_auc_merged))))\n",
    "\n",
    "\n",
    "# pyplot_piano_roll(test.dataset[1][:, :NUM_NOTES],\n",
    "#                   cmap=\"Greens\", low_lim=LOW_LIM, high_lim=HIGH_LIM)\n",
    "# plt.title(\"Test target (ground truth)\")\n",
    "\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (13, 4)\n",
    "pyplot_piano_roll(merged_output,\n",
    "                  cmap=\"Greens\", low_lim=LOW_LIM, high_lim=HIGH_LIM)\n",
    "plt.title(\"Target (labels)\")\n",
    "plt.ylim(CROP)\n",
    "plt.savefig(PLOTS / \"roll1.png\")\n",
    "pyplot_piano_roll(merged_pred[:, :NUM_NOTES],\n",
    "                  cmap=\"Blues\", low_lim=LOW_LIM, high_lim=HIGH_LIM)\n",
    "plt.title(\"Predictions\")\n",
    "plt.ylim(CROP)\n",
    "plt.savefig(PLOTS / \"roll2.png\")\n",
    "pyplot_piano_roll(merged_input[:, :NUM_NOTES],\n",
    "                  cmap=\"Reds\", low_lim=LOW_LIM, high_lim=HIGH_LIM)\n",
    "plt.title(\"Baseline (equal to inputs)\")\n",
    "plt.ylim(CROP)\n",
    "plt.savefig(PLOTS / \"roll3.png\")\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
