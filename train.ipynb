{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"Main script.\"\"\"\n",
    "from tensorflow.keras.callbacks import TensorBoard, CSVLogger\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import model as mod\n",
    "import dataset\n",
    "from dataset import plot_piano_roll\n",
    "from pathlib import Path\n",
    "import time\n",
    "\n",
    "# P = Path(__file__).parent.absolute()\n",
    "P = Path(os.path.abspath(''))  # Compatible with Jupyter Notebook\n",
    "\n",
    "FS = 10  # Sampling frequency\n",
    "BS = 64  # Batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " \"\"\"Run main script.\"\"\"\n",
    "# Load midi files.\n",
    "midi_list = [x for x in os.listdir(P / \"data\") if x.endswith('.mid')]\n",
    "st = 20\n",
    "num_ts = 10\n",
    "\n",
    "# All dataset\n",
    "train_list = midi_list[0:165]\n",
    "validation_list = midi_list[166:213]\n",
    "test_list = midi_list[213:236]\n",
    "\n",
    "# Small dataset\n",
    "# train_list = midi_list[0:50]\n",
    "# validation_list = midi_list[50:60]\n",
    "# test_list = midi_list[61:65]\n",
    "\n",
    "print(\"Train list:  \", train_list)\n",
    "print(\"Validation list:  \", validation_list)\n",
    "print(\"Test list:  \", test_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Build Keras model.\n",
    "model = mod.build_model((st, 88), num_ts)\n",
    "now = datetime.now()\n",
    "\n",
    "# Save logs\n",
    "logger = TensorBoard(log_dir=P / 'logs' / now.strftime(\"%Y%m%d-%H%M%S\"),\n",
    "                     write_graph=True, update_freq='epoch')\n",
    "\n",
    "csv_logger = CSVLogger(P / 'logs' / (now.strftime(\"%Y%m%d-%H%M%S\") + '-' +\n",
    "                       str(st) + '-' + str(num_ts) + '.csv'),\n",
    "                       separator=',', append=False)\n",
    "# Create generators.\n",
    "train = dataset.DataGenerator(train_list, P / \"data\",  fs=FS)\n",
    "validation = dataset.DataGenerator(validation_list, P / \"data\",  fs=FS)\n",
    "test = dataset.DataGenerator(test_list, P / \"data\",  fs=FS)\n",
    "train.build_dataset(\"training\", step=st, t_step=num_ts)\n",
    "validation.build_dataset(\"validation\", step=st, t_step=num_ts)\n",
    "test.build_dataset(\"test\", step=st, t_step=num_ts)\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model.\n",
    "# model.fit(train.generate(limit=epochs), epochs=epochs,\n",
    "#           steps_per_epoch=1,  shuffle=True,\n",
    "#           validation_data=validation.generate(limit=epochs),\n",
    "#           validation_steps=1,\n",
    "#           callbacks=[logger, csv_logger])\n",
    "epochs = 10\n",
    "start = time.time()\n",
    "history = model.fit(x=train.dataset[0], y=train.dataset[1],\n",
    "                    epochs=epochs, batch_size=BS, shuffle=True,\n",
    "                    validation_data=(validation.dataset[0],\n",
    "                                     validation.dataset[1]),\n",
    "                    callbacks=[logger, csv_logger])\n",
    "end = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model.\n",
    "print(\"Evaluation on test set:\")\n",
    "_, prec, rec, f1, f2 = model.evaluate(x=test.dataset[0],\n",
    "                                      y=test.dataset[1],\n",
    "                                      batch_size=BS)\n",
    "# _, prec, rec, f1 = model.evaluate(test.generate(limit=epochs),\n",
    "#                                   steps=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(x=test.dataset[0])\n",
    "print(\"Pred shape: \", predictions.shape)\n",
    "predictions = predictions[:, 0:88]\n",
    "print(predictions.shape)\n",
    "print(test.dataset[0].shape, \"\\n\\n\\n\")\n",
    "test = test.dataset[0][:, 0, :]\n",
    "predictions = dataset.transpose(predictions)\n",
    "predictions = dataset.convert(predictions)\n",
    "# test = test[:, 0, :]\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 5))\n",
    "plot_piano_roll(dataset.transpose(test), 21, 109, ax1, FS)\n",
    "ax1.set_title('Test')\n",
    "\n",
    "plot_piano_roll(predictions, 21, 109, ax2, FS)\n",
    "ax2.set_title('Predictions')\n",
    "plt.show()\n",
    "print(\"Training time: \", (end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
