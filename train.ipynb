{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a FF network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"Main script used for training.\"\"\"\n",
    "from tensorflow.keras.callbacks import TensorBoard, CSVLogger\n",
    "from tensorflow.keras.models import load_model\n",
    "import keras.metrics\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import os\n",
    "from nmp import model as mod\n",
    "from nmp import dataset, ev_metrics\n",
    "from nmp.dataset import pyplot_piano_roll\n",
    "from nmp import plotter\n",
    "from pathlib import Path\n",
    "import time\n",
    "import math\n",
    "import pypianoroll\n",
    "from pypianoroll import Multitrack, Track\n",
    "import numpy as np\n",
    "import random\n",
    "import copy\n",
    "import tensorflow as tf\n",
    "\n",
    "# NOTES = '-' + 'no-down'\n",
    "NOTES = '-' + 'ff'\n",
    "\n",
    "# P = Path(__file__).parent.absolute()\n",
    "P = Path(os.path.abspath(''))  # Compatible with Jupyter Notebook\n",
    "P2 = Path('S:\\datasets')  # Dataset path\n",
    "\n",
    "PLOTS = P / 'plots'  # Plots path\n",
    "FS = 24  # Sampling frequency. 10 Hz = 100 ms\n",
    "Q = 0  # Quantize?\n",
    "st = 10  # Past timesteps\n",
    "num_ts = 10  # Predicted timesteps\n",
    "DOWN = 12  # Downsampling factor\n",
    "D = \"data/Piano-midi.de\"  # Dataset\n",
    "\n",
    "# D = \"data/Nottingham\"  # Dataset\n",
    "# D = \"data/JSB Chorales\"  # Dataset\n",
    "# D = \"data/MuseData\"  # Dataset\n",
    "\n",
    "# 64 notes\n",
    "LOW_LIM = 33  # A1\n",
    "HIGH_LIM = 97  # C7\n",
    "\n",
    "# LOW_LIM = 36  # C2\n",
    "# HIGH_LIM = 85  # C6\n",
    "\n",
    "# Complete 88-key keyboard\n",
    "# LOW_LIM = 21  # A0\n",
    "# HIGH_LIM = 109  # C8\n",
    "\n",
    "NUM_NOTES = HIGH_LIM - LOW_LIM\n",
    "CROP = [LOW_LIM, HIGH_LIM]  # Crop plots\n",
    "\n",
    "LOAD = 0\n",
    "TRANS = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate list of MIDI files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_list = [x for x in os.listdir(P / D / 'train') if x.endswith('.mid')]\n",
    "validation_list = [x for x in os.listdir(P / D / 'valid') if x.endswith('.mid')]\n",
    "test_list = [x for x in os.listdir(P / D / 'test') if x.endswith('.mid')]\n",
    "\n",
    "    \n",
    "# if D == \"data/piano-midi\":  # Piano dataset\n",
    "#     midi_list = [x for x in os.listdir(P / D) if x.endswith('.mid')]\n",
    "#     train_list = midi_list[0:165]\n",
    "#     validation_list = midi_list[166:213]\n",
    "#     test_list = midi_list[213:236]\n",
    "\n",
    "\n",
    "# if D == \"data/JSB-Chorales-dataset\":  # Synth dataset\n",
    "#     train_list = [P / D / Df]\n",
    "#     validation_list = [P / D / Df]\n",
    "#     test_list = [P / D / Df]\n",
    "\n",
    "# else:\n",
    "#     print(\"Total number of MIDI files:\", len(midi_list))\n",
    "\n",
    "# Small dataset\n",
    "# train_list = midi_list[0:15]\n",
    "# validation_list = midi_list[55:65]\n",
    "# test_list = midi_list[161:163]\n",
    "\n",
    "print(\"\\nTrain list:  \", train_list)\n",
    "print(\"\\nValidation list:  \", validation_list)\n",
    "print(\"\\nTest list:  \", test_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets\n",
    "### Load datasets from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train = dataset.Dataset([], '')\n",
    "# train.dataset = (np.load(P2 / 'train.input.npy', allow_pickle=True),\n",
    "#                  np.load(P2 / 'train.target.npy', allow_pickle=True))\n",
    "# validation = dataset.Dataset([], '')\n",
    "# validation.dataset = (np.load(P2 / 'valid.input.npy', allow_pickle=True),\n",
    "#                       np.load(P2 / 'valid.target.npy', allow_pickle=True))\n",
    "# test = dataset.Dataset([], '')\n",
    "# test.dataset = (np.load(P2 / 'test.input.npy', allow_pickle=True),\n",
    "#                 np.load(P2 / 'test.target.npy', allow_pickle=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate data from lists\n",
    "Training, validation and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "if D == \"data/JSB-Chorales-dataset\":\n",
    "    train = dataset.Dataset(train_list, P / D,  fs=FS, bl=0, quant=Q)\n",
    "    train.build_choral(\"train\", step=st, t_step=num_ts, steps=st,\n",
    "                       low_lim=LOW_LIM, high_lim=HIGH_LIM)   \n",
    "    validation = dataset.Dataset(validation_list, P / D,  fs=FS, bl=0, quant=Q)\n",
    "    validation.build_choral(\"valid\", step=st, t_step=num_ts, steps=st,\n",
    "                       low_lim=LOW_LIM, high_lim=HIGH_LIM) \n",
    "    test = dataset.Dataset(test_list, P / D,  fs=FS, bl=0, quant=Q)\n",
    "    test.build_choral(\"test\", step=st, t_step=num_ts, steps=st,\n",
    "                       low_lim=LOW_LIM, high_lim=HIGH_LIM) \n",
    "\n",
    "else:\n",
    "    train = dataset.Dataset(train_list, P / D / 'train',  fs=FS, bl=0, quant=Q)\n",
    "    validation = dataset.Dataset(validation_list, P / D / 'valid',  fs=FS, bl=0, quant=Q)\n",
    "    test = dataset.Dataset(test_list, P / D / 'test',  fs=FS, bl=0, quant=Q)\n",
    "\n",
    "    train.build_dataset(\"training\", step=st, t_step=num_ts, steps=st,\n",
    "                        down=DOWN, low_lim=LOW_LIM, high_lim=HIGH_LIM)\n",
    "    validation.build_dataset(\"validation\", step=st, t_step=num_ts, steps=st,\n",
    "                             down=DOWN, low_lim=LOW_LIM, high_lim=HIGH_LIM)\n",
    "    test.build_dataset(\"test\", step=st, t_step=num_ts, steps=st,\n",
    "                       down=DOWN, low_lim=LOW_LIM, high_lim=HIGH_LIM)\n",
    "\n",
    "end = time.time()\n",
    "print(\"Done\")\n",
    "print(\"Loading time: %.2f\" % (end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train.dataset[0].shape)\n",
    "print(train.dataset[1].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save(P2 / '64-18-step' / 'train.input', train.dataset[0], allow_pickle=True)\n",
    "# np.save(P2 / '64-18-step' / 'train.target', train.dataset[1], allow_pickle=True)\n",
    "# np.save(P2 / '64-18-step' / 'valid.input', validation.dataset[0], allow_pickle=True)\n",
    "# np.save(P2 / '64-18-step' / 'valid.target', validation.dataset[1], allow_pickle=True)\n",
    "# np.save(P2 / '64-18-step' / 'test.input', test.dataset[0], allow_pickle=True)\n",
    "# np.save(P2 / '64-18-step' / 'test.target', test.dataset[1], allow_pickle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Piano rolls of training dataset\n",
    "Input and output piano rolls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (20, 8)\n",
    "pyplot_piano_roll(train.dataset[0][:, 0, :],\n",
    "                  low_lim=LOW_LIM, high_lim=HIGH_LIM)\n",
    "plt.title(\"Train data\")\n",
    "plt.ylim(CROP)\n",
    "pyplot_piano_roll(train.dataset[1][:, :NUM_NOTES], cmap=\"Oranges\",\n",
    "                  low_lim=LOW_LIM, high_lim=HIGH_LIM)\n",
    "plt.title(\"Train target\")\n",
    "plt.ylim(CROP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras\n",
    "### Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOAD = 0\n",
    "model_path = str(P / 'models' / 'model-down-trans-64-4-20epochs')\n",
    "BS = 64  # Batch size\n",
    "import importlib\n",
    "importlib.reload(mod)\n",
    "importlib.reload(dataset)\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# L = train.dataset[0].shape[0]\n",
    "# L -= L % BS\n",
    "# x = train.dataset[0][:L, :, :]\n",
    "# y = train.dataset[1][:L, :]\n",
    "# train.dataset = (x, y)\n",
    "\n",
    "# L = validation.dataset[0].shape[0]\n",
    "# L -= L % BS\n",
    "# x = validation.dataset[0][:L, :, :]\n",
    "# y = validation.dataset[1][:L, :]\n",
    "# validation.dataset = (x, y)\n",
    "\n",
    "# train.dataset[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if LOAD:\n",
    "    model = load_model(filepath=model_path,\n",
    "                       custom_objects=None,\n",
    "                       compile=True)\n",
    "\n",
    "else:\n",
    "    model = mod.build_model((st, NUM_NOTES), (num_ts), NUM_NOTES, BS)\n",
    "    mod.compile_model(model, 'binary_crossentropy', 'adam',\n",
    "                      metrics=['accuracy', mod.f1, keras.metrics.Precision(), keras.metrics.Recall()])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "now = datetime.now()\n",
    "\n",
    "# Save logs\n",
    "logger = TensorBoard(log_dir=P / 'logs' / now.strftime(\"%Y%m%d-%H%M%S\"),\n",
    "                     write_graph=True, update_freq='epoch')\n",
    "\n",
    "csv_logger = CSVLogger(P / 'logs' / (now.strftime(\"%Y%m%d-%H%M%S\") + '-' +\n",
    "                       str(st) + '-' + str(num_ts) + '.csv'),\n",
    "                       separator=',', append=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory where the checkpoints will be saved\n",
    "checkpoint_dir = P / ('models/training_checkpoints/' + now.strftime(\"%Y%m%d-%H%M%S\"))\n",
    "# Name of the checkpoint files\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
    "\n",
    "checkpoint_callback=tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_prefix,\n",
    "    save_weights_only=True,\n",
    "    save_best_only=True,\n",
    "    period=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit the model\n",
    "Define batch size ```BS``` and number of ```epochs```\n",
    "\n",
    "#### Fit with reset_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Fit generator the model.\n",
    "# random.seed(40)\n",
    "# epochs = 1\n",
    "# start = time.time()\n",
    "# train_loss = []\n",
    "# train_acc = []\n",
    "# val_loss = []\n",
    "\n",
    "# size_valid = math.floor(validation.dataset[0].shape[0] / BS)\n",
    "# spe_valid = size_valid\n",
    "\n",
    "# cnt = 0\n",
    "# choice = list(range(len(train.data)))\n",
    "# for _ in range(20):  # Epochs\n",
    "#     random.shuffle(choice)\n",
    "#     print(\"List: \", choice)\n",
    "#     song = 0\n",
    "#     train_song_loss = []\n",
    "#     train_song_acc = []\n",
    "#     val_song_loss = []\n",
    "#     last_song = 0\n",
    "    \n",
    "#     for i in choice:\n",
    "# #         print(\"song\", i)\n",
    "#         x = copy.deepcopy(train.data[i])\n",
    "#         y = copy.deepcopy(train.targets[i])\n",
    "#         song += 1\n",
    "#         if song == len(train.data):\n",
    "#             last_song = 1\n",
    "        \n",
    "#         size_train = math.floor(len(x) / BS)\n",
    "#         spe_train = math.floor(size_train / 10)\n",
    "\n",
    "#         if not last_song:\n",
    "#             history = model.fit(dataset.generate_stateful((x[:size_train*BS, :, :],\n",
    "#                                                            y[:size_train*BS, :]), bs=BS, trans=1), epochs=epochs,\n",
    "#                                 steps_per_epoch=spe_train, verbose=0)    \n",
    "# #             print(\"s\", song)\n",
    "                   \n",
    "#         else:\n",
    "#             history = model.fit(dataset.generate_stateful((x, y), bs=BS, trans=1), epochs=epochs,\n",
    "#                       steps_per_epoch=spe_train,\n",
    "#                       validation_data=dataset.generate((validation.dataset[0][:size_valid*BS, :, :],\n",
    "#                                                         validation.dataset[1][:size_valid*BS, :]), bs=BS),\n",
    "#                       validation_steps=spe_valid, verbose=1)\n",
    "#             print(\"Epoch %d finished\" % cnt)\n",
    "#             cnt += 1\n",
    "\n",
    "#             train_song_loss.append(history.history['loss'])\n",
    "#             train_song_acc.append(history.history['accuracy'])\n",
    "#             val_song_loss.append(history.history['val_loss'])\n",
    "\n",
    "\n",
    "        \n",
    "#         model.reset_states()\n",
    "    \n",
    "#     train_loss.append(np.mean(train_song_loss))\n",
    "#     train_acc.append(np.mean(train_song_acc))\n",
    "#     val_loss.append(np.mean(val_song_loss))\n",
    "    \n",
    "#     end = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(constrained_layout=True, figsize=(5, 4))\n",
    "# plt.plot(val_loss, 'o-', c='tab:orange', label='Validation', ms=8, alpha=0.8)\n",
    "# plt.plot(train_loss, 'o-', c='tab:red', label='Train', ms=8, alpha=0.8)\n",
    "# plt.xlabel('Epoch')\n",
    "# plt.xticks(range(epochs))\n",
    "# plt.legend()\n",
    "# plt.title('Loss: Binary cross-entropy')\n",
    "# ax.spines['top'].set_visible(False)\n",
    "# ax.spines['right'].set_visible(False)\n",
    "# plt.ylim([0.000, 0.30])\n",
    "# fig.savefig(PLOTS / 'lossLSTMDe.eps', fmt='eps')\n",
    "# print(\"Training time: \", (end-start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### train_on_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Train on batch the model.\n",
    "# BS = 5  # Batch size\n",
    "# epochs = 3\n",
    "# start = time.time()\n",
    "# history = {'train': [], 'test': []}\n",
    "# for e in range(epochs):\n",
    "#     print(\"Epoch %d\" % e)\n",
    "#     data_generator = dataset.generate_on_batch((train.data, train.targets), bs=BS, trans=1)\n",
    "#     while True:\n",
    "#         try:\n",
    "#             (x, y) = next(data_generator)\n",
    "# #             print(\"Sample\")\n",
    "# #             time.sleep(.5)\n",
    "\n",
    "#             if x[0][0][0] >= 0:\n",
    "#                 history['train'].append(model.train_on_batch(x, y))\n",
    "#             else:\n",
    "# #                 print(\"Resetting state...\")\n",
    "#                 model.reset_states()\n",
    "\n",
    "#         except Exception:\n",
    "#             print(\"Epoch %d finished!\" % e)\n",
    "#             break\n",
    "\n",
    "# end = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_generator = dataset.generate_on_batch((test.data, test.targets), bs=BS, trans=1)\n",
    "# while True:\n",
    "#     try:\n",
    "#         (x, y) = next(data_generator)\n",
    "\n",
    "#         if x[0][0][0] >= 0:\n",
    "#             history['test'].append(model.train_on_batch(x, y))\n",
    "#         else:\n",
    "#             model.reset_states()\n",
    "#     except Exception:\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(constrained_layout=True)\n",
    "# plt.plot(history['train'])\n",
    "# plt.legend(['Loss', 'Accuracy'])\n",
    "\n",
    "# plt.figure(constrained_layout=True)\n",
    "# plt.plot(history['test'])\n",
    "# plt.legend(['Loss', 'Accuracy'])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### fit generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit generator the model.\n",
    "epochs = 30\n",
    "start = time.time()\n",
    "size_train = math.ceil(train.dataset[0].shape[0] / BS)\n",
    "spe_train = size_train\n",
    "size_valid = math.ceil(validation.dataset[0].shape[0] / BS)\n",
    "spe_valid = size_valid\n",
    "print(\"Train dataset shape: \", train.dataset[0].shape, \"\\n\")\n",
    "print(\"Train dataset target shape: \", train.dataset[1].shape, \"\\n\")\n",
    "\n",
    "# Fit generator. Data should be shuffled before fitting.\n",
    "history = model.fit(dataset.generate((train.dataset[0], train.dataset[1]), trans=1), epochs=epochs,\n",
    "          steps_per_epoch=spe_train,\n",
    "          validation_data=dataset.generate((validation.dataset[0], validation.dataset[1])),\n",
    "          validation_steps=spe_valid,\n",
    "          callbacks=[logger, csv_logger, checkpoint_callback])\n",
    "\n",
    "end = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Fit the model.\n",
    "\n",
    "# BS = 64  # Batch size\n",
    "# epochs = 25\n",
    "# start = time.time()\n",
    "# # size_train = math.ceil(train.dataset[0].shape[0] / BS)\n",
    "# # spe_train = size_train #+ size_train*10\n",
    "# # size_valid = math.ceil(validation.dataset[0].shape[0] / BS)\n",
    "# # spe_valid = size_valid #+ size_valid*10\n",
    "# print(\"Train dataset shape: \", train.dataset[0].shape, \"\\n\")\n",
    "# print(\"Train dataset target shape: \", train.dataset[1].shape, \"\\n\")\n",
    "\n",
    "# # Normal fit. Auto-shuffles data.\n",
    "# history = model.fit(x=train.dataset[0], y=train.dataset[1],\n",
    "#                     epochs=epochs, batch_size=BS, shuffle=True,\n",
    "#                     validation_data=(validation.dataset[0],\n",
    "#                                      validation.dataset[1]),\n",
    "#                     callbacks=[logger, csv_logger])\n",
    "\n",
    "# end = time.time()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # Fit the model.\n",
    "# BS = 64  # Batch size\n",
    "# epochs = 25\n",
    "# start = time.time()\n",
    "# # size_train = math.ceil(train.dataset[0].shape[0] / BS)\n",
    "# # spe_train = size_train #+ size_train*10\n",
    "# # size_valid = math.ceil(validation.dataset[0].shape[0] / BS)\n",
    "# # spe_valid = size_valid #+ size_valid*10\n",
    "# print(\"Train dataset shape: \", train.dataset[0].shape, \"\\n\")\n",
    "# print(\"Train dataset target shape: \", train.dataset[1].shape, \"\\n\")\n",
    "\n",
    "# # Normal fit. Auto-shuffles data.\n",
    "# history = model.fit(x, epochs=epochs, shuffle=True,\n",
    "#                     validation_data=(validation.dataset[0],\n",
    "#                                      validation.dataset[1]),\n",
    "#                     callbacks=[logger, csv_logger])\n",
    "\n",
    "# end = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### History\n",
    "\n",
    "```f1_first```: F1-score on first predicted timestep\n",
    "\n",
    "```f1_last```: F1-score on last predicted timestep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"\\nTraining time: \", (end-start), \"\\n\")\n",
    "hist = pd.DataFrame(history.history)\n",
    "print(hist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot loss function of training and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(constrained_layout=True, figsize=(6, 4))\n",
    "\n",
    "plt.plot(hist['loss'], '-', c='tab:red', label='Train', ms=8, alpha=0.8)\n",
    "plt.plot(hist['val_loss'], '-', c='tab:orange', label='Validation', ms=8, alpha=0.8)\n",
    "\n",
    "plt.xlabel('Epoch', fontsize='x-large')\n",
    "# plt.xticks(range(epochs))\n",
    "plt.legend(fontsize='x-large')\n",
    "plt.title('Loss: Binary cross-entropy', fontsize='x-large')\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "# plt.ylim([0.12, 0.16])\n",
    "# fig.savefig(PLOTS / 'comp-ff-loss.pdf')\n",
    "print(\"Training time: \", (end-start))\n",
    "\n",
    "ax = plt.gca()\n",
    "ax.tick_params(labelsize='x-large')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hist['loss'].to_csv(('tables/ff-' + D[5:] + '-loss-train-' + str(BS) + NOTES + '.dat').lower(), sep=' ', header=None)\n",
    "# hist['val_loss'].to_csv(('tables/ff-' + D[5:] + '-loss-valid-' + str(BS) + NOTES + '.dat').lower(), sep=' ', header=None)\n",
    "\n",
    "# hist['f1'].to_csv(('tables/ff-' + D[5:] + '-f1-train-' + str(BS) + NOTES + '.dat').lower(), sep=' ', header=None)\n",
    "# hist['val_f1'].to_csv(('tables/ff-' + D[5:] + '-f1-valid-' + str(BS) + NOTES + '.dat').lower(), sep=' ', header=None)\n",
    "\n",
    "# hist['precision_1'].to_csv(('tables/ff-' + D[5:] + '-precision-train-' + str(BS) + NOTES + '.dat').lower(), sep=' ', header=None)\n",
    "# hist['val_precision_1'].to_csv(('tables/ff-' + D[5:] + '-precision-valid-' + str(BS) + NOTES + '.dat').lower(), sep=' ', header=None)\n",
    "\n",
    "# hist['recall_1'].to_csv(('tables/ff-' + D[5:] + '-recall-train-' + str(BS) + NOTES + '.dat').lower(), sep=' ', header=None)\n",
    "# hist['val_recall_1'].to_csv(('tables/ff-' + D[5:] + '-recall-valid-' + str(BS) + NOTES + '.dat').lower(), sep=' ', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(constrained_layout=True, figsize=(6, 4))\n",
    "\n",
    "plt.plot(hist['f1'], 's-', c='tab:blue', label='Train', ms=8, alpha=0.8)\n",
    "plt.plot(hist['val_f1'], 'o-', c='tab:orange', label='Validation', ms=8, alpha=0.8)\n",
    "\n",
    "plt.xlabel('Epoch', fontsize='x-large')\n",
    "# plt.xticks(range(epochs))\n",
    "plt.legend(fontsize='x-large')\n",
    "plt.title('F1 Score', fontsize='x-large')\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "# plt.ylim([0.12, 0.16])\n",
    "# fig.savefig(PLOTS / 'f120480.pdf', fmt='pdf', dpi=300)\n",
    "print(\"Training time: \", (end-start))\n",
    "\n",
    "ax = plt.gca()\n",
    "ax.tick_params(labelsize='x-large')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(constrained_layout=True, figsize=(6, 4))\n",
    "\n",
    "plt.plot(hist['recall_1'], 's-', c='tab:blue', label='Train', ms=8, alpha=0.8)\n",
    "plt.plot(hist['val_recall_1'], 'o-', c='tab:orange', label='Validation', ms=8, alpha=0.8)\n",
    "\n",
    "plt.xlabel('Epoch', fontsize='x-large')\n",
    "# plt.xticks(range(epochs))\n",
    "plt.legend(fontsize='x-large')\n",
    "plt.title('Recall', fontsize='x-large')\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "# plt.ylim([0.12, 0.16])\n",
    "# fig.savefig(PLOTS / 'recall.pdf', fmt='pdf', dpi=300)\n",
    "print(\"Training time: \", (end-start))\n",
    "\n",
    "ax = plt.gca()\n",
    "ax.tick_params(labelsize='x-large')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(constrained_layout=True, figsize=(6, 4))\n",
    "\n",
    "plt.plot(hist['precision_1'], 's-', c='tab:blue', label='Train', ms=8, alpha=0.8)\n",
    "plt.plot(hist['val_precision_1'], 'o-', c='tab:orange', label='Validation', ms=8, alpha=0.8)\n",
    "\n",
    "plt.xlabel('Epoch', fontsize='x-large')\n",
    "# plt.xticks(range(epochs))\n",
    "plt.legend(fontsize='x-large')\n",
    "plt.title('Precision', fontsize='x-large')\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "# plt.ylim([0.12, 0.16])\n",
    "# fig.savefig(PLOTS / 'precision.pdf', fmt='pdf', dpi=300)\n",
    "print(\"Training time: \", (end-start))\n",
    "\n",
    "ax = plt.gca()\n",
    "ax.tick_params(labelsize='x-large')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save model to file\n",
    "Model can be loaded with:\n",
    "``` python\n",
    "load_model(filepath=str(folder_path), compile=True)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save(str(P / 'models' / 'ff-z2-de'))\n",
    "# model.save(str(P / 'models' / 'lstm-z-de') + '.h5', save_format='h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = mod.build_model((st, NUM_NOTES), (num_ts), NUM_NOTES, BS)\n",
    "mod.compile_model(model, 'binary_crossentropy', 'adam',\n",
    "                  metrics=['accuracy', mod.f1, keras.metrics.Precision(), keras.metrics.Recall()])\n",
    "model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
    "model.build(tf.TensorShape([1, None]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Evaluation on train set:\")\n",
    "e_train = model.evaluate(x=train.dataset[0],\n",
    "                         y=train.dataset[1],\n",
    "                         batch_size=BS)\n",
    "\n",
    "print(\"\\nEvaluation on validation set:\")\n",
    "e_valid = model.evaluate(x=validation.dataset[0],\n",
    "                         y=validation.dataset[1],\n",
    "                         batch_size=BS)\n",
    "\n",
    "print(\"\\nEvaluation on test set:\")\n",
    "e_test = model.evaluate(x=test.dataset[0],\n",
    "                        y=test.dataset[1],\n",
    "                        batch_size=BS)\n",
    "\n",
    "results = {out: e_train[i] for i, out in enumerate(model.metrics_names)}\n",
    "res = pd.DataFrame(list(results.items()), columns=['metric', 'train'])\n",
    "res = res.set_index('metric')\n",
    "\n",
    "results2 = {out: e_valid[i] for i, out in enumerate(model.metrics_names)}\n",
    "res2 = pd.DataFrame(list(results2.items()), columns=['metric', 'validation'])\n",
    "res2 = res2.set_index('metric')\n",
    "\n",
    "results3 = {out: e_test[i] for i, out in enumerate(model.metrics_names)}\n",
    "res3 = pd.DataFrame(list(results3.items()), columns=['metric', 'test'])\n",
    "res3 = res3.set_index('metric')\n",
    "\n",
    "\n",
    "result = pd.concat([res, res2, res3], axis=1, sort=False)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make predictions\n",
    "Predictions from test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = test.dataset[0].shape[0]\n",
    "# L -= L % BS\n",
    "predictions = model.predict(x=test.dataset[0][:L, :, :])\n",
    "predictions_bin = dataset.threshold(predictions)\n",
    "# print(\"Pred shape: \", predictions.shape)\n",
    "# predictions = predictions[:, 88*0:88*1]  # First timestep\n",
    "# print(\"Test shape: \", test.dataset[1].shape, \"\\n\\n\\n\")\n",
    "# test2 = test.dataset[1][:, :88]  # First timestep\n",
    "# prediction_new = dataset.transpose(predictions)\n",
    "# prediction_new = dataset.convert(prediction_new)\n",
    "# fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 5))\n",
    "# plot_piano_roll(dataset.transpose(test2), 21, 109, ax1, FS)\n",
    "# ax1.set_title('Test  target')\n",
    "\n",
    "# plot_piano_roll(prediction_new, 21, 109, ax2, FS)\n",
    "# ax2.set_title('Test predictions')\n",
    "\n",
    "pyplot_piano_roll(test.dataset[1][:, :NUM_NOTES],\n",
    "                  cmap=\"Greens\", low_lim=LOW_LIM, high_lim=HIGH_LIM)\n",
    "plt.title(\"Test target (ground truth)\")\n",
    "plt.ylim(CROP)\n",
    "\n",
    "pyplot_piano_roll(predictions[:, :NUM_NOTES],\n",
    "                  cmap=\"Purples\", low_lim=LOW_LIM, high_lim=HIGH_LIM)\n",
    "plt.title(\"Test predictions (not thresholded)\")\n",
    "plt.ylim(CROP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate AUC - ROC\n",
    "Evaluate metric on predictions and baseline with respect to the ground truth of test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build baseline\n",
    "if D == \"data/JSB-Chorales-dataset\":\n",
    "    baseline = dataset.Dataset(test_list, P / D / 'test',  fs=FS, bl=1, quant=Q)\n",
    "    baseline.build_choral(\"test\", step=st, t_step=num_ts, steps=st,\n",
    "                       low_lim=LOW_LIM, high_lim=HIGH_LIM)\n",
    "\n",
    "else:\n",
    "    baseline = dataset.Dataset(test_list, P / D / 'test',  fs=FS, bl=1, quant=Q)\n",
    "    baseline.build_dataset(\"baseline\", step=st, t_step=num_ts, steps=st,\n",
    "                           down=DOWN, low_lim=LOW_LIM, high_lim=HIGH_LIM)\n",
    "\n",
    "print(\"\")\n",
    "print(\"Baseline shape: \", baseline.dataset[1].shape)\n",
    "print(\"Test shape: \", test.dataset[1].shape)\n",
    "\n",
    "pred_auc = ev_metrics.compute_auc(test.dataset[1][:L, :], predictions, NUM_NOTES)\n",
    "base_auc = ev_metrics.compute_auc(test.dataset[1][:L, :], baseline.dataset[1][:L, :], NUM_NOTES)\n",
    "# pred_auc = ev_metrics.compute_auc(test.dataset[1], predictions, NUM_NOTES)\n",
    "# base_auc = ev_metrics.compute_auc(test.dataset[1], baseline.dataset[1], NUM_NOTES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2, axcb) = plt.subplots(1, 3, constrained_layout=True,\n",
    "                                     figsize=(8, 8),\n",
    "                                     gridspec_kw={'width_ratios':[1, 1, 0.08]})\n",
    "g1 = sns.heatmap(pred_auc, vmin=0.5, vmax=1, cmap='copper', ax=ax1, cbar=False)\n",
    "g1.set_ylabel('')\n",
    "g1.set_xlabel('')\n",
    "g1.set_yticklabels(g1.get_yticklabels(), rotation=0)\n",
    "ax1.set_xlabel('Time (step)')\n",
    "ax1.set_ylabel('Pitch')\n",
    "ax1.set_title('AUC-ROC (prediction)')\n",
    "g2 = sns.heatmap(base_auc, vmin=0.5, vmax=1, cmap='copper', ax=ax2, cbar_ax=axcb)\n",
    "g2.set_ylabel('')\n",
    "g2.set_xlabel('')\n",
    "g2.set_yticks([])\n",
    "ax2.set_xlabel('Time (step)')\n",
    "ax2.set_title('AUC-ROC (baseline)')\n",
    "ax1.get_shared_y_axes().join(ax1,ax2)\n",
    "plt.savefig(PLOTS / 'heat.eps', format='eps')\n",
    "print(pred_auc.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c1 = 0\n",
    "c2 = 64\n",
    "fig, (ax1, ax2, axcb) = plt.subplots(1, 3, constrained_layout=True,\n",
    "                                     figsize=(8, 6),\n",
    "                                     gridspec_kw={'width_ratios':[1, 1, 0.08]})\n",
    "g1 = sns.heatmap(pred_auc[c1:c2], vmin=0.5, vmax=1, cmap='gray', ax=ax1, cbar=False)\n",
    "g1.set_ylabel('')\n",
    "g1.set_xlabel('')\n",
    "g1.set_yticklabels(g1.get_yticklabels(), rotation=0)\n",
    "ax1.set_xlabel('Time (step)')\n",
    "ax1.set_ylabel('Pitch')\n",
    "ax1.set_title('AUC-ROC (crop) [prediction]')\n",
    "g2 = sns.heatmap(base_auc[c1:c2], vmin=0.5, vmax=1, cmap='gray', ax=ax2, cbar_ax=axcb)\n",
    "g2.set_ylabel('')\n",
    "g2.set_xlabel('')\n",
    "g2.set_yticks([])\n",
    "ax2.set_xlabel('Time (step)')\n",
    "ax2.set_title('AUC-ROC (crop) [baseline]')\n",
    "ax1.get_shared_y_axes().join(ax1,ax2)\n",
    "plt.savefig(PLOTS / 'heat_crop.eps', format='eps')\n",
    "print(pred_auc.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(constrained_layout=True, figsize=(5, 4))\n",
    "\n",
    "ax.plot(range(1, num_ts + 1), np.mean(pred_auc[c1:c2]), 'x', c='tab:blue', label='prediction', ms=10)\n",
    "ax.plot(range(1, num_ts + 1), np.mean(base_auc[c1:c2]), 'o', c='tab:green', label='baseline ', ms=7)\n",
    "\n",
    "ax.set_ylim([0.4, 1])\n",
    "ax.set_ylim([0.4, 1])\n",
    "ax.legend()\n",
    "plt.title('Avg. AUC-ROC per predicted timestep')\n",
    "plt.xlabel('Timestep')\n",
    "# plt.xticks([0, 2, 4, 6, 8, 10])\n",
    "plt.ylabel('ROC AUC')\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "name = 'auc' + str()\n",
    "plt.grid()\n",
    "# plt.savefig(PLOTS / 'aucDe222.eps', format='eps')\n",
    "# fig.savefig(PLOTS / 'comp-ff-auc.pdf')\n",
    "print(\"Predict. mean value:\", np.mean(np.mean(pred_auc[c1:c2])))\n",
    "print(\"Baseline mean value:\", np.mean(np.mean(base_auc[c1:c2])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(pred_auc[c1:c2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(base_auc[c1:c2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# auc_df = pd.DataFrame(\n",
    "#     {'pred': np.mean(pred_auc[c1:c2]),\n",
    "#      'base': np.mean(base_auc[c1:c2])})\n",
    "# auc_df['pred'].to_csv(('tables/ff-' + D[5:] + '-auc-pred-' + str(BS) + NOTES + '.dat').lower(), sep=' ', header=None)\n",
    "# auc_df['base'].to_csv(('tables/ff-' + D[5:] + '-auc-base-' + str(BS) + NOTES + '.dat').lower(), sep=' ', header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Piano rolls\n",
    "- test data (input of the network)\n",
    "\n",
    "- test target (ground truth)\n",
    "\n",
    "- model predictions (output of the network)\n",
    "\n",
    "- baseline (repetition of  the last input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t=0  # Timestep to visualize\n",
    "plt.rcParams[\"figure.figsize\"] = (10, 4)\n",
    "pyplot_piano_roll(test.dataset[0][:, 0, :],\n",
    "                  cmap=\"Blues\", low_lim=LOW_LIM, high_lim=HIGH_LIM)\n",
    "plt.title(\"Test data (input)\")\n",
    "plt.ylim(CROP)\n",
    "# plt.savefig(PLOTS / ('pr' + str(t) + 'data.png'))\n",
    "\n",
    "pyplot_piano_roll(predictions[:, NUM_NOTES*t:NUM_NOTES*(t+1)],\n",
    "                  cmap=\"Purples\", low_lim=LOW_LIM, high_lim=HIGH_LIM)\n",
    "plt.title(\"Predictions\")\n",
    "plt.ylim(CROP)\n",
    "# plt.savefig(PLOTS / ('pr' + str(t) + 'pred.png'))\n",
    "\n",
    "pyplot_piano_roll(test.dataset[1][:, NUM_NOTES*t:NUM_NOTES*(t+1)],\n",
    "                  cmap=\"Greens\", low_lim=LOW_LIM, high_lim=HIGH_LIM)\n",
    "plt.title(\"Test target (ground truth)\")\n",
    "plt.ylim(CROP)\n",
    "# plt.savefig(PLOTS / ('pr' + str(t) + 'target.png'))\n",
    "\n",
    "pyplot_piano_roll(baseline.dataset[1][:, NUM_NOTES*t:NUM_NOTES*(t+1)],\n",
    "                  cmap=\"Reds\", low_lim=LOW_LIM, high_lim=HIGH_LIM)\n",
    "plt.title(\"Baseline\")\n",
    "plt.ylim(CROP)\n",
    "# plt.savefig(PLOTS / ('pr' + str(t) + 'base.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t=0  # Timestep to visualize\n",
    "plt.rcParams[\"figure.figsize\"] = (10, 4)\n",
    "pyplot_piano_roll(predictions[:, NUM_NOTES*t:NUM_NOTES*(t+1)],\n",
    "                  cmap=\"Greys\", low_lim=LOW_LIM, high_lim=HIGH_LIM)\n",
    "plt.title(\"Predictions\")\n",
    "plt.ylim([50, 80])\n",
    "# plt.savefig(PLOTS / ('pr' + str(t) + 'predn.png'))\n",
    "\n",
    "t=4  # Timestep to visualize\n",
    "pyplot_piano_roll(predictions[:, NUM_NOTES*t:NUM_NOTES*(t+1)],\n",
    "                  cmap=\"Greys\", low_lim=LOW_LIM, high_lim=HIGH_LIM)\n",
    "plt.title(\"Predictions\")\n",
    "plt.ylim([50, 80])\n",
    "# plt.savefig(PLOTS / ('pr' + str(t) + 'predn.png'))\n",
    "\n",
    "t=7  # Timestep to visualize\n",
    "pyplot_piano_roll(predictions[:, NUM_NOTES*t:NUM_NOTES*(t+1)], \n",
    "                  cmap=\"Greys\", low_lim=LOW_LIM, high_lim=HIGH_LIM)\n",
    "plt.title(\"Predictions\")\n",
    "plt.ylim([50, 80])\n",
    "# plt.savefig(PLOTS / ('pr' + str(t) + 'predn.png'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional tests\n",
    "Piano dataset, cmaj scale,..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# midi_list2 = [x for x in os.listdir(P / \"data\") if x.endswith('.mid')]\n",
    "# test_new = midi_list2[0:3]\n",
    "# test = dataset.DataGenerator(test_new, P / \"data\",  fs=FS, bl=0, quant=Q)\n",
    "# test.build_dataset(\"test\", step=st, t_step=num_ts)\n",
    "# print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.rcParams[\"figure.figsize\"] = (20, 8)\n",
    "# predictions = model.predict(x=test.dataset[0])\n",
    "# predictions_bin = dataset.convert(predictions)\n",
    "\n",
    "# print(\"Test shape: \", test.dataset[0].shape)\n",
    "# print(\"Pred shape: \", predictions_bin.shape)\n",
    "\n",
    "# pyplot_piano_roll(predictions_bin[:, :88], cmap=\"Purples\")\n",
    "# plt.title(\"Predictions\")\n",
    "# plt.ylim(CROP)\n",
    "\n",
    "# pyplot_piano_roll(test.dataset[1][:, :88], cmap=\"Greens\")\n",
    "# plt.title(\"Test target (ground truth)\")\n",
    "# plt.ylim(CROP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Build baseline\n",
    "# baseline = dataset.DataGenerator(test_new, P / \"data\",  fs=FS, bl=1, quant=Q)\n",
    "# baseline.build_dataset(\"baseline\", step=st, t_step=num_ts)\n",
    "# print(\"\")\n",
    "# print(\"Baseline shape: \", baseline.dataset[1].shape)\n",
    "# print(\"Test shape: \", test.dataset[1].shape)\n",
    "# print(\"Prediction shape: \", predictions_bin.shape)\n",
    "# print(\"--- --- ---\")\n",
    "# pred_auc2 = ev_metrics.compute_auc(test.dataset[1], predictions)\n",
    "# base_auc2 = ev_metrics.compute_auc(test.dataset[1], baseline.dataset[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, (ax1, ax2, axcb) = plt.subplots(1, 3, constrained_layout=True,\n",
    "#                                      figsize=(12, 8),\n",
    "#                                      gridspec_kw={'width_ratios':[1, 1, 0.08]})\n",
    "# g1 = sns.heatmap(pred_auc2[c1:c2], vmin=0.5, vmax=1, cmap='gray', ax=ax1, cbar=False)\n",
    "# g1.set_ylabel('')\n",
    "# g1.set_xlabel('')\n",
    "# ax1.set_xlabel('Time (step)')\n",
    "# ax1.set_ylabel('Pitch')\n",
    "# ax1.set_title('AUC-ROC (prediction)')\n",
    "# g2 = sns.heatmap(base_auc2[c1:c2], vmin=0.5, vmax=1, cmap='gray', ax=ax2, cbar_ax=axcb)\n",
    "# g2.set_ylabel('')\n",
    "# g2.set_xlabel('')\n",
    "# g2.set_yticks([])\n",
    "# ax2.set_xlabel('Time (step)')\n",
    "# ax2.set_title('AUC-ROC (baseline)')\n",
    "# ax1.get_shared_y_axes().join(ax1,ax2)\n",
    "\n",
    "# print(pred_auc.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(constrained_layout=True, figsize=(5, 4))\n",
    "\n",
    "# ax.plot(range(1, num_ts + 1), np.mean(pred_auc2[c1:c2]), 'x', c='tab:blue', label='prediction', ms=10)\n",
    "# ax.plot(range(1, num_ts + 1), np.mean(base_auc2[c1:c2]), 'o', c='tab:green', label='baseline ', ms=7)\n",
    "\n",
    "# ax.set_ylim([0.4, 1])\n",
    "# ax.set_ylim([0.4, 1])\n",
    "# ax.legend()\n",
    "# plt.title('Avg. AUC-ROC (crop) per predicted timestep')\n",
    "# plt.xlabel('Timestep')\n",
    "# # plt.xticks([0, 2, 4, 6, 8, 10])\n",
    "# plt.ylabel('ROC AUC')\n",
    "# ax.spines['top'].set_visible(False)\n",
    "# ax.spines['right'].set_visible(False)\n",
    "# name = 'auc' + str()\n",
    "# # plt.savefig(PLOTS / 'auc.eps', format='eps')\n",
    "\n",
    "# print(\"Predict. mean value:\", np.mean(np.mean(pred_auc[c1:c2])))\n",
    "# print(\"Baseline mean value:\", np.mean(np.mean(base_auc[c1:c2])))"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
