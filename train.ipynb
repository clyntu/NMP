{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"Main script used for training.\"\"\"\n",
    "from tensorflow.keras.callbacks import TensorBoard, CSVLogger\n",
    "from tensorflow.keras.models import load_model\n",
    "import keras.metrics\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import os\n",
    "from nmp import model as mod\n",
    "from nmp import dataset, ev_metrics\n",
    "from nmp.dataset import pyplot_piano_roll\n",
    "from nmp import plotter\n",
    "from pathlib import Path\n",
    "import time\n",
    "import math\n",
    "import pypianoroll\n",
    "from pypianoroll import Multitrack, Track\n",
    "import numpy as np\n",
    "\n",
    "# P = Path(__file__).parent.absolute()\n",
    "P = Path(os.path.abspath(''))  # Compatible with Jupyter Notebook\n",
    "P2 = Path('S:\\datasets')  # Dataset path\n",
    "\n",
    "PLOTS = P / 'plots'  # Plots path\n",
    "FS = 24  # Sampling frequency. 10 Hz = 100 ms\n",
    "Q = 0  # Quantize?\n",
    "st = 10  # Past timesteps\n",
    "num_ts = 10  # Predicted timesteps\n",
    "DOWN = 12  # Downsampling factor\n",
    "D = \"data\"  # Dataset (synth or data)\n",
    "CROP = [21, 109]  # Crop plots\n",
    "\n",
    "LOAD = 0\n",
    "TRANS = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate list of MIDI files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "midi_list = [x for x in os.listdir(P / D) if x.endswith('.mid')]\n",
    "print(\"Total number of MIDI files:\", len(midi_list))\n",
    "\n",
    "if D == \"data\":  # Piano dataset\n",
    "    train_list = midi_list[0:165]\n",
    "    validation_list = midi_list[166:213]\n",
    "    test_list = midi_list[213:236]\n",
    "\n",
    "if D == \"synth\":  # Synth dataset\n",
    "    train_list = midi_list[0:2500]\n",
    "    validation_list = midi_list[2500:3000]\n",
    "    test_list = midi_list[3000:4000]\n",
    "\n",
    "# Small dataset\n",
    "# train_list = midi_list[0:5]\n",
    "# validation_list = midi_list[5:7]\n",
    "# test_list = midi_list[161:163]\n",
    "\n",
    "# print(\"\\nTrain list:  \", train_list)\n",
    "# print(\"\\nValidation list:  \", validation_list)\n",
    "# print(\"\\nTest list:  \", test_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets\n",
    "### Load datasets from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train = dataset.Dataset([], '')\n",
    "# train.dataset = (np.load(P2 / 'train.input.npy', allow_pickle=True),\n",
    "#                  np.load(P2 / 'train.target.npy', allow_pickle=True))\n",
    "# validation = dataset.Dataset([], '')\n",
    "# validation.dataset = (np.load(P2 / 'valid.input.npy', allow_pickle=True),\n",
    "#                       np.load(P2 / 'valid.target.npy', allow_pickle=True))\n",
    "# test = dataset.Dataset([], '')\n",
    "# test.dataset = (np.load(P2 / 'test.input.npy', allow_pickle=True),\n",
    "#                 np.load(P2 / 'test.target.npy', allow_pickle=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate data from lists\n",
    "Training, validation and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "train = dataset.Dataset(train_list, P / D,  fs=FS, bl=0, quant=Q)\n",
    "validation = dataset.Dataset(validation_list, P / D,  fs=FS, bl=0, quant=Q)\n",
    "test = dataset.Dataset(test_list, P / D,  fs=FS, bl=0, quant=Q)\n",
    "\n",
    "train.build_dataset(\"training\", step=st, t_step=num_ts, steps=st, down=DOWN)\n",
    "validation.build_dataset(\"validation\", step=st, t_step=num_ts, steps=st, down=DOWN)\n",
    "test.build_dataset(\"test\", step=st, t_step=num_ts, steps=st, down=DOWN)\n",
    "\n",
    "end = time.time()\n",
    "print(\"Done\")\n",
    "print(\"Loading time: %.2f\" % (end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.dataset[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save(P2 / '64-18-step' / 'train.input', train.dataset[0], allow_pickle=True)\n",
    "# np.save(P2 / '64-18-step' / 'train.target', train.dataset[1], allow_pickle=True)\n",
    "# np.save(P2 / '64-18-step' / 'valid.input', validation.dataset[0], allow_pickle=True)\n",
    "# np.save(P2 / '64-18-step' / 'valid.target', validation.dataset[1], allow_pickle=True)\n",
    "# np.save(P2 / '64-18-step' / 'test.input', test.dataset[0], allow_pickle=True)\n",
    "# np.save(P2 / '64-18-step' / 'test.target', test.dataset[1], allow_pickle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Piano rolls of training dataset\n",
    "Input and output piano rolls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (20, 8)\n",
    "pyplot_piano_roll(train.dataset[0][:, 0, :])\n",
    "plt.title(\"Train data\")\n",
    "plt.ylim(CROP)\n",
    "pyplot_piano_roll(train.dataset[1][:, :88], cmap=\"Oranges\")\n",
    "plt.title(\"Train target\")\n",
    "plt.ylim(CROP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras\n",
    "### Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOAD = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if LOAD:\n",
    "    model = load_model(filepath=str(P / 'models' / 'model-down-trans-64-4-20epochs'),\n",
    "                       custom_objects=None,\n",
    "                       compile=True)\n",
    "\n",
    "else:\n",
    "    model = mod.build_model((st, 88), (num_ts))\n",
    "    mod.compile_model(model, 'binary_crossentropy', 'adam',\n",
    "                      metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "now = datetime.now()\n",
    "\n",
    "# Save logs\n",
    "logger = TensorBoard(log_dir=P / 'logs' / now.strftime(\"%Y%m%d-%H%M%S\"),\n",
    "                     write_graph=True, update_freq='epoch')\n",
    "\n",
    "csv_logger = CSVLogger(P / 'logs' / (now.strftime(\"%Y%m%d-%H%M%S\") + '-' +\n",
    "                       str(st) + '-' + str(num_ts) + '.csv'),\n",
    "                       separator=',', append=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit the model\n",
    "Define batch size ```BS``` and number of ```epochs```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit generator the model.\n",
    "BS = 64  # Batch size\n",
    "epochs = 25\n",
    "start = time.time()\n",
    "size_train = math.ceil(train.dataset[0].shape[0] / BS)\n",
    "spe_train = size_train\n",
    "size_valid = math.ceil(validation.dataset[0].shape[0] / BS)\n",
    "spe_valid = size_valid\n",
    "print(\"Train dataset shape: \", train.dataset[0].shape, \"\\n\")\n",
    "print(\"Train dataset target shape: \", train.dataset[1].shape, \"\\n\")\n",
    "\n",
    "# Fit generator. Data should be shuffled before fitting.\n",
    "history = model.fit(dataset.generate((train.dataset[0], train.dataset[1]), trans=1), epochs=epochs,\n",
    "          steps_per_epoch=spe_train,\n",
    "          validation_data=dataset.generate((validation.dataset[0], validation.dataset[1])),\n",
    "          validation_steps=spe_valid,\n",
    "          callbacks=[logger, csv_logger])\n",
    "\n",
    "end = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Fit the model.\n",
    "\n",
    "# BS = 64  # Batch size\n",
    "# epochs = 10\n",
    "# start = time.time()\n",
    "# # size_train = math.ceil(train.dataset[0].shape[0] / BS)\n",
    "# # spe_train = size_train #+ size_train*10\n",
    "# # size_valid = math.ceil(validation.dataset[0].shape[0] / BS)\n",
    "# # spe_valid = size_valid #+ size_valid*10\n",
    "# print(\"Train dataset shape: \", train.dataset[0].shape, \"\\n\")\n",
    "# print(\"Train dataset target shape: \", train.dataset[1].shape, \"\\n\")\n",
    "\n",
    "# # Normal fit. Auto-shuffles data.\n",
    "# history = model.fit(x=train.dataset[0], y=train.dataset[1],\n",
    "#                     epochs=epochs, batch_size=BS, shuffle=True,\n",
    "#                     validation_data=(validation.dataset[0],\n",
    "#                                      validation.dataset[1]),\n",
    "#                     callbacks=[logger, csv_logger])\n",
    "\n",
    "# end = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### History\n",
    "\n",
    "```f1_first```: F1-score on first predicted timestep\n",
    "\n",
    "```f1_last```: F1-score on last predicted timestep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nTraining time: \", (end-start), \"\\n\")\n",
    "hist = pd.DataFrame(history.history)\n",
    "print(hist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot loss function of training and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(constrained_layout=True, figsize=(5, 4))\n",
    "plt.plot(hist['val_loss'], 'o-', c='tab:orange', label='Validation', ms=8, alpha=0.8)\n",
    "plt.plot(hist['loss'], 'o-', c='tab:red', label='Train', ms=8, alpha=0.8)\n",
    "plt.xlabel('Epoch')\n",
    "plt.xticks(range(epochs))\n",
    "plt.legend()\n",
    "plt.title('Loss: Binary cross-entropy')\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "fig.savefig(PLOTS / 'loss.eps', fmt='eps')\n",
    "print(\"Training time: \", (end-start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save model to file\n",
    "Model can be loaded with:\n",
    "``` python\n",
    "load_model(filepath=str(folder_path), compile=True)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save(str(P / 'models' / 'model-RNN-12-10'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Evaluation on train set:\")\n",
    "e_train = model.evaluate(x=train.dataset[0],\n",
    "                         y=train.dataset[1],\n",
    "                         batch_size=BS)\n",
    "\n",
    "print(\"\\nEvaluation on validation set:\")\n",
    "e_valid = model.evaluate(x=validation.dataset[0],\n",
    "                         y=validation.dataset[1],\n",
    "                         batch_size=BS)\n",
    "\n",
    "print(\"\\nEvaluation on test set:\")\n",
    "e_test = model.evaluate(x=test.dataset[0],\n",
    "                        y=test.dataset[1],\n",
    "                        batch_size=BS)\n",
    "\n",
    "results = {out: e_train[i] for i, out in enumerate(model.metrics_names)}\n",
    "res = pd.DataFrame(list(results.items()), columns=['metric', 'train'])\n",
    "res = res.set_index('metric')\n",
    "\n",
    "results2 = {out: e_valid[i] for i, out in enumerate(model.metrics_names)}\n",
    "res2 = pd.DataFrame(list(results2.items()), columns=['metric', 'validation'])\n",
    "res2 = res2.set_index('metric')\n",
    "\n",
    "results3 = {out: e_test[i] for i, out in enumerate(model.metrics_names)}\n",
    "res3 = pd.DataFrame(list(results3.items()), columns=['metric', 'test'])\n",
    "res3 = res3.set_index('metric')\n",
    "\n",
    "\n",
    "result = pd.concat([res, res2, res3], axis=1, sort=False)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make predictions\n",
    "Predictions from test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(x=test.dataset[0])\n",
    "predictions_bin = dataset.convert(predictions)\n",
    "# print(\"Pred shape: \", predictions.shape)\n",
    "# predictions = predictions[:, 88*0:88*1]  # First timestep\n",
    "# print(\"Test shape: \", test.dataset[1].shape, \"\\n\\n\\n\")\n",
    "# test2 = test.dataset[1][:, :88]  # First timestep\n",
    "# prediction_new = dataset.transpose(predictions)\n",
    "# prediction_new = dataset.convert(prediction_new)\n",
    "# fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 5))\n",
    "# plot_piano_roll(dataset.transpose(test2), 21, 109, ax1, FS)\n",
    "# ax1.set_title('Test  target')\n",
    "\n",
    "# plot_piano_roll(prediction_new, 21, 109, ax2, FS)\n",
    "# ax2.set_title('Test predictions')\n",
    "\n",
    "pyplot_piano_roll(test.dataset[1][:, :88], cmap=\"Greens\")\n",
    "plt.title(\"Test target (ground truth)\")\n",
    "plt.ylim(CROP)\n",
    "\n",
    "pyplot_piano_roll(predictions_bin[:, :88], cmap=\"Purples\")\n",
    "plt.title(\"Test predictions\")\n",
    "plt.ylim(CROP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate AUC - ROC\n",
    "Evaluate metric on predictions and baseline with respect to the ground truth of test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build baseline\n",
    "baseline = dataset.Dataset(test_list, P / D,  fs=FS, bl=1, quant=Q)\n",
    "baseline.build_dataset(\"baseline\", step=st, t_step=num_ts, steps=st, down=DOWN)\n",
    "\n",
    "print(\"\")\n",
    "print(\"Baseline shape: \", baseline.dataset[1].shape)\n",
    "print(\"Test shape: \", test.dataset[1].shape)\n",
    "\n",
    "pred_auc = ev_metrics.compute_auc(test.dataset[1], predictions)\n",
    "base_auc = ev_metrics.compute_auc(test.dataset[1], baseline.dataset[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2, axcb) = plt.subplots(1, 3, constrained_layout=True,\n",
    "                                     figsize=(8, 8),\n",
    "                                     gridspec_kw={'width_ratios':[1, 1, 0.08]})\n",
    "g1 = sns.heatmap(pred_auc, vmin=0.5, vmax=1, cmap='copper', ax=ax1, cbar=False)\n",
    "g1.set_ylabel('')\n",
    "g1.set_xlabel('')\n",
    "g1.set_yticklabels(g1.get_yticklabels(), rotation=0)\n",
    "ax1.set_xlabel('Time (step)')\n",
    "ax1.set_ylabel('Pitch')\n",
    "ax1.set_title('AUC-ROC (prediction)')\n",
    "g2 = sns.heatmap(base_auc, vmin=0.5, vmax=1, cmap='copper', ax=ax2, cbar_ax=axcb)\n",
    "g2.set_ylabel('')\n",
    "g2.set_xlabel('')\n",
    "g2.set_yticks([])\n",
    "ax2.set_xlabel('Time (step)')\n",
    "ax2.set_title('AUC-ROC (baseline)')\n",
    "ax1.get_shared_y_axes().join(ax1,ax2)\n",
    "plt.savefig(PLOTS / 'heat.eps', format='eps')\n",
    "print(pred_auc.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c1 = 25\n",
    "c2 = 70\n",
    "fig, (ax1, ax2, axcb) = plt.subplots(1, 3, constrained_layout=True,\n",
    "                                     figsize=(8, 6),\n",
    "                                     gridspec_kw={'width_ratios':[1, 1, 0.08]})\n",
    "g1 = sns.heatmap(pred_auc[c1:c2], vmin=0.5, vmax=1, cmap='gray', ax=ax1, cbar=False)\n",
    "g1.set_ylabel('')\n",
    "g1.set_xlabel('')\n",
    "g1.set_yticklabels(g1.get_yticklabels(), rotation=0)\n",
    "ax1.set_xlabel('Time (step)')\n",
    "ax1.set_ylabel('Pitch')\n",
    "ax1.set_title('AUC-ROC (crop) [prediction]')\n",
    "g2 = sns.heatmap(base_auc[c1:c2], vmin=0.5, vmax=1, cmap='gray', ax=ax2, cbar_ax=axcb)\n",
    "g2.set_ylabel('')\n",
    "g2.set_xlabel('')\n",
    "g2.set_yticks([])\n",
    "ax2.set_xlabel('Time (step)')\n",
    "ax2.set_title('AUC-ROC (crop) [baseline]')\n",
    "ax1.get_shared_y_axes().join(ax1,ax2)\n",
    "plt.savefig(PLOTS / 'heat_crop.eps', format='eps')\n",
    "print(pred_auc.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(constrained_layout=True, figsize=(5, 4))\n",
    "\n",
    "ax.plot(range(1, num_ts + 1), np.mean(pred_auc[c1:c2]), 'x', c='tab:blue', label='prediction', ms=10)\n",
    "ax.plot(range(1, num_ts + 1), np.mean(base_auc[c1:c2]), 'o', c='tab:green', label='baseline ', ms=7)\n",
    "\n",
    "ax.set_ylim([0.4, 1])\n",
    "ax.set_ylim([0.4, 1])\n",
    "ax.legend()\n",
    "plt.title('Avg. AUC-ROC per predicted timestep')\n",
    "plt.xlabel('Timestep')\n",
    "# plt.xticks([0, 2, 4, 6, 8, 10])\n",
    "plt.ylabel('ROC AUC')\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "name = 'auc' + str()\n",
    "plt.savefig(PLOTS / 'auc.eps', format='eps')\n",
    "\n",
    "print(\"Predict. mean value:\", np.mean(np.mean(pred_auc[c1:c2])))\n",
    "print(\"Baseline mean value:\", np.mean(np.mean(base_auc[c1:c2])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Piano rolls\n",
    "- test data (input of the network)\n",
    "\n",
    "- test target (ground truth)\n",
    "\n",
    "- model predictions (output of the network)\n",
    "\n",
    "- baseline (repetition of  the last input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t=0  # Timestep to visualize\n",
    "plt.rcParams[\"figure.figsize\"] = (10, 4)\n",
    "pyplot_piano_roll(test.dataset[0][:, 0, :], cmap=\"Blues\")\n",
    "plt.title(\"Test data (input)\")\n",
    "plt.ylim(CROP)\n",
    "plt.savefig(PLOTS / ('pr' + str(t) + 'data.png'))\n",
    "\n",
    "pyplot_piano_roll(predictions[:, 88*t:88*(t+1)], cmap=\"Purples\")\n",
    "plt.title(\"Predictions\")\n",
    "plt.ylim(CROP)\n",
    "plt.savefig(PLOTS / ('pr' + str(t) + 'pred.png'))\n",
    "\n",
    "pyplot_piano_roll(test.dataset[1][:, 88*t:88*(t+1)], cmap=\"Greens\")\n",
    "plt.title(\"Test target (ground truth)\")\n",
    "plt.ylim(CROP)\n",
    "plt.savefig(PLOTS / ('pr' + str(t) + 'target.png'))\n",
    "\n",
    "pyplot_piano_roll(baseline.dataset[1][:, 88*t:88*(t+1)], cmap=\"Reds\")\n",
    "plt.title(\"Baseline\")\n",
    "plt.ylim(CROP)\n",
    "plt.savefig(PLOTS / ('pr' + str(t) + 'base.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t=0  # Timestep to visualize\n",
    "plt.rcParams[\"figure.figsize\"] = (10, 4)\n",
    "pyplot_piano_roll(predictions[:, 88*t:88*(t+1)], cmap=\"Greys\")\n",
    "plt.title(\"Predictions\")\n",
    "plt.ylim([50, 80])\n",
    "plt.savefig(PLOTS / ('pr' + str(t) + 'predn.png'))\n",
    "\n",
    "t=4  # Timestep to visualize\n",
    "pyplot_piano_roll(predictions[:, 88*t:88*(t+1)], cmap=\"Greys\")\n",
    "plt.title(\"Predictions\")\n",
    "plt.ylim([50, 80])\n",
    "plt.savefig(PLOTS / ('pr' + str(t) + 'predn.png'))\n",
    "\n",
    "t=7  # Timestep to visualize\n",
    "pyplot_piano_roll(predictions[:, 88*t:88*(t+1)], cmap=\"Greys\")\n",
    "plt.title(\"Predictions\")\n",
    "plt.ylim([50, 80])\n",
    "plt.savefig(PLOTS / ('pr' + str(t) + 'predn.png'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional tests\n",
    "Piano dataset, cmaj scale,..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# midi_list2 = [x for x in os.listdir(P / \"data\") if x.endswith('.mid')]\n",
    "# test_new = midi_list2[0:3]\n",
    "# test = dataset.DataGenerator(test_new, P / \"data\",  fs=FS, bl=0, quant=Q)\n",
    "# test.build_dataset(\"test\", step=st, t_step=num_ts)\n",
    "# print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.rcParams[\"figure.figsize\"] = (20, 8)\n",
    "# predictions = model.predict(x=test.dataset[0])\n",
    "# predictions_bin = dataset.convert(predictions)\n",
    "\n",
    "# print(\"Test shape: \", test.dataset[0].shape)\n",
    "# print(\"Pred shape: \", predictions_bin.shape)\n",
    "\n",
    "# pyplot_piano_roll(predictions_bin[:, :88], cmap=\"Purples\")\n",
    "# plt.title(\"Predictions\")\n",
    "# plt.ylim(CROP)\n",
    "\n",
    "# pyplot_piano_roll(test.dataset[1][:, :88], cmap=\"Greens\")\n",
    "# plt.title(\"Test target (ground truth)\")\n",
    "# plt.ylim(CROP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Build baseline\n",
    "# baseline = dataset.DataGenerator(test_new, P / \"data\",  fs=FS, bl=1, quant=Q)\n",
    "# baseline.build_dataset(\"baseline\", step=st, t_step=num_ts)\n",
    "# print(\"\")\n",
    "# print(\"Baseline shape: \", baseline.dataset[1].shape)\n",
    "# print(\"Test shape: \", test.dataset[1].shape)\n",
    "# print(\"Prediction shape: \", predictions_bin.shape)\n",
    "# print(\"--- --- ---\")\n",
    "# pred_auc2 = ev_metrics.compute_auc(test.dataset[1], predictions)\n",
    "# base_auc2 = ev_metrics.compute_auc(test.dataset[1], baseline.dataset[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, (ax1, ax2, axcb) = plt.subplots(1, 3, constrained_layout=True,\n",
    "#                                      figsize=(12, 8),\n",
    "#                                      gridspec_kw={'width_ratios':[1, 1, 0.08]})\n",
    "# g1 = sns.heatmap(pred_auc2[c1:c2], vmin=0.5, vmax=1, cmap='gray', ax=ax1, cbar=False)\n",
    "# g1.set_ylabel('')\n",
    "# g1.set_xlabel('')\n",
    "# ax1.set_xlabel('Time (step)')\n",
    "# ax1.set_ylabel('Pitch')\n",
    "# ax1.set_title('AUC-ROC (prediction)')\n",
    "# g2 = sns.heatmap(base_auc2[c1:c2], vmin=0.5, vmax=1, cmap='gray', ax=ax2, cbar_ax=axcb)\n",
    "# g2.set_ylabel('')\n",
    "# g2.set_xlabel('')\n",
    "# g2.set_yticks([])\n",
    "# ax2.set_xlabel('Time (step)')\n",
    "# ax2.set_title('AUC-ROC (baseline)')\n",
    "# ax1.get_shared_y_axes().join(ax1,ax2)\n",
    "\n",
    "# print(pred_auc.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(constrained_layout=True, figsize=(5, 4))\n",
    "\n",
    "# ax.plot(range(1, num_ts + 1), np.mean(pred_auc2[c1:c2]), 'x', c='tab:blue', label='prediction', ms=10)\n",
    "# ax.plot(range(1, num_ts + 1), np.mean(base_auc2[c1:c2]), 'o', c='tab:green', label='baseline ', ms=7)\n",
    "\n",
    "# ax.set_ylim([0.4, 1])\n",
    "# ax.set_ylim([0.4, 1])\n",
    "# ax.legend()\n",
    "# plt.title('Avg. AUC-ROC (crop) per predicted timestep')\n",
    "# plt.xlabel('Timestep')\n",
    "# # plt.xticks([0, 2, 4, 6, 8, 10])\n",
    "# plt.ylabel('ROC AUC')\n",
    "# ax.spines['top'].set_visible(False)\n",
    "# ax.spines['right'].set_visible(False)\n",
    "# name = 'auc' + str()\n",
    "# # plt.savefig(PLOTS / 'auc.eps', format='eps')\n",
    "\n",
    "# print(\"Predict. mean value:\", np.mean(np.mean(pred_auc[c1:c2])))\n",
    "# print(\"Baseline mean value:\", np.mean(np.mean(base_auc[c1:c2])))"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
