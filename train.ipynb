{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"Main script.\"\"\"\n",
    "from tensorflow.keras.callbacks import TensorBoard, CSVLogger\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "import model as mod\n",
    "import dataset\n",
    "from dataset import plot_piano_roll\n",
    "from pathlib import Path\n",
    "from plotter import smooth\n",
    "import time\n",
    "import math\n",
    "import ev_metrics\n",
    "\n",
    "# P = Path(__file__).parent.absolute()\n",
    "P = Path(os.path.abspath(''))  # Compatible with Jupyter Notebook\n",
    "\n",
    "FS = 10  # Sampling frequency. 10 Hz = 100 ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load midi files.\n",
    "midi_list = [x for x in os.listdir(P / \"data\") if x.endswith('.mid')]\n",
    "st = 10\n",
    "num_ts = 10\n",
    "\n",
    "# All dataset\n",
    "train_list = midi_list[0:165]\n",
    "validation_list = midi_list[166:213]\n",
    "test_list = midi_list[213:236]\n",
    "\n",
    "# Small dataset\n",
    "# train_list = midi_list[0:20]\n",
    "# validation_list = midi_list[20:30]\n",
    "# test_list = midi_list[61:65]\n",
    "\n",
    "print(\"Train list:  \", train_list)\n",
    "print(\"Validation list:  \", validation_list)\n",
    "print(\"Test list:  \", test_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create generators.\n",
    "BASELINE = 0\n",
    "train = dataset.DataGenerator(train_list, P / \"data\",  fs=FS, bl=BASELINE)\n",
    "validation = dataset.DataGenerator(validation_list, P / \"data\",  fs=FS, bl=BASELINE)\n",
    "test = dataset.DataGenerator(test_list, P / \"data\",  fs=FS, bl=0)\n",
    "train.build_dataset(\"training\", step=st, t_step=num_ts)\n",
    "validation.build_dataset(\"validation\", step=st, t_step=num_ts)\n",
    "test.build_dataset(\"test\", step=st, t_step=num_ts)\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train.dataset[0].shape)\n",
    "print(train.dataset[0][:,0,:].shape)\n",
    "print(train.dataset[1][:,0:88].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data augmentation\n",
    "# train.build_transposed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Build Keras model.\n",
    "model = mod.build_model((st, 88), num_ts)\n",
    "model.summary()\n",
    "now = datetime.now()\n",
    "\n",
    "# Save logs\n",
    "logger = TensorBoard(log_dir=P / 'logs' / now.strftime(\"%Y%m%d-%H%M%S\"),\n",
    "                     write_graph=True, update_freq='epoch')\n",
    "\n",
    "csv_logger = CSVLogger(P / 'logs' / (now.strftime(\"%Y%m%d-%H%M%S\") + '-' +\n",
    "                       str(st) + '-' + str(num_ts) + '.csv'),\n",
    "                       separator=',', append=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model.\n",
    "\n",
    "BS = 64  # Batch size\n",
    "epochs = 10\n",
    "start = time.time()\n",
    "size_train = math.ceil(train.dataset[0].shape[0] / BS)\n",
    "spe_train = size_train #+ size_train*10\n",
    "size_valid = math.ceil(validation.dataset[0].shape[0] / BS)\n",
    "spe_valid = size_valid #+ size_valid*10\n",
    "print(\"Train dataset shape: \", train.dataset[0].shape, \"\\n\")\n",
    "\n",
    "# Fit generator. Data should be shuffled before fitting.\n",
    "# history = model.fit(train.generate(bs=BS, limit=epochs, trans=0, name='train'), epochs=epochs,\n",
    "#           steps_per_epoch=spe_train,\n",
    "#           validation_data=validation.generate(bs=BS, limit=epochs, trans=0, name='valid'),\n",
    "#           validation_steps=spe_valid,\n",
    "#           shuffle=True,\n",
    "#           callbacks=[logger, csv_logger])\n",
    "\n",
    "\n",
    "# Normal fit. Auto-shuffles data.\n",
    "history = model.fit(x=train.dataset[0], y=train.dataset[1],\n",
    "                    epochs=epochs, batch_size=BS, shuffle=True,\n",
    "                    validation_data=(validation.dataset[0],\n",
    "                                     validation.dataset[1]),\n",
    "                    callbacks=[logger, csv_logger])\n",
    "\n",
    "end = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = pd.DataFrame(history.history)\n",
    "print(hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(constrained_layout=True, figsize=(5, 4))\n",
    "# plt.plot(smooth(hist['val_f1_first']), label='First')\n",
    "# plt.plot(smooth(hist['val_f1_second']), label='Second')\n",
    "# plt.plot(smooth(hist['val_f1_last']), label='Last')\n",
    "\n",
    "# plt.plot(smooth(hist['val_f1_2']), label='2')\n",
    "# plt.plot(smooth(hist['val_f1_3']), label='3')\n",
    "# plt.plot(smooth(hist['val_f1_4']), label='4')\n",
    "# plt.plot(smooth(hist['val_f1_5']), label='5')\n",
    "# plt.plot(smooth(hist['val_f1_6']), label='6')\n",
    "# plt.plot(smooth(hist['val_f1_7']), label='7')\n",
    "# plt.plot(smooth(hist['val_f1_8']), label='8')\n",
    "\n",
    "# plt.plot(smooth(hist['val_f1_first']), label='Validation')\n",
    "# plt.plot(smooth(hist['f1_first']), label='Train')\n",
    "\n",
    "plt.plot(smooth(hist['val_loss']), 'x-', c='tab:orange', label='Validation', ms=8)\n",
    "plt.plot(smooth(hist['loss']), 'ro-', c='tab:red', label='Train')\n",
    "plt.xlabel('Epoch')\n",
    "plt.xticks(range(epochs))\n",
    "plt.legend()\n",
    "plt.title('Loss: Binary cross-entropy')\n",
    "plt.savefig('loss.eps', format='eps')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model.\n",
    "print(\"Evaluation on train set:\")\n",
    "e_train = model.evaluate(x=train.dataset[0],\n",
    "                         y=train.dataset[1],\n",
    "                         batch_size=BS)\n",
    "\n",
    "print(\"\\nEvaluation on validation set:\")\n",
    "e_valid = model.evaluate(x=validation.dataset[0],\n",
    "                         y=validation.dataset[1],\n",
    "                         batch_size=BS)\n",
    "\n",
    "print(\"\\nEvaluation on test set:\")\n",
    "e_test = model.evaluate(x=test.dataset[0],\n",
    "                        y=test.dataset[1],\n",
    "                        batch_size=BS)\n",
    "\n",
    "results = {out: e_train[i] for i, out in enumerate(model.metrics_names)}\n",
    "res = pd.DataFrame(list(results.items()), columns=['metric', 'train'])\n",
    "res = res.set_index('metric')\n",
    "\n",
    "results2 = {out: e_valid[i] for i, out in enumerate(model.metrics_names)}\n",
    "res2 = pd.DataFrame(list(results2.items()), columns=['metric', 'validation'])\n",
    "res2 = res2.set_index('metric')\n",
    "\n",
    "results3 = {out: e_test[i] for i, out in enumerate(model.metrics_names)}\n",
    "res3 = pd.DataFrame(list(results3.items()), columns=['metric', 'test'])\n",
    "res3 = res3.set_index('metric')\n",
    "\n",
    "\n",
    "result = pd.concat([res, res2, res3], axis=1, sort=False)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test = dataset.DataGenerator(test_list, P / \"data\",  fs=FS, bl=0)\n",
    "# test.build_dataset(\"test\", step=st, t_step=num_ts)\n",
    "\n",
    "predictions = model.predict(x=test.dataset[0])\n",
    "print(\"Pred shape: \", predictions.shape)\n",
    "predictions = predictions[:, 88*0:88*1]\n",
    "print(predictions.shape)\n",
    "print(test.dataset[0].shape, \"\\n\\n\\n\")\n",
    "test2 = test.dataset[0][:, 0, :]\n",
    "predictions2 = dataset.transpose(predictions)\n",
    "predictions2 = dataset.convert(predictions2)\n",
    "# test = test[:, 0, :]\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 5))\n",
    "plot_piano_roll(dataset.transpose(test2), 21, 109, ax1, FS)\n",
    "ax1.set_title('Test')\n",
    "\n",
    "plot_piano_roll(predictions2, 21, 109, ax2, FS)\n",
    "ax2.set_title('Predictions')\n",
    "plt.show()\n",
    "print(\"Training time: \", (end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "importlib.reload(ev_metrics)\n",
    "\n",
    "predictions = model.predict(x=test.dataset[0])\n",
    "baseline = dataset.DataGenerator(test_list, P / \"data\",  fs=FS, bl=1)\n",
    "baseline.build_dataset(\"test\", step=st, t_step=num_ts)\n",
    "baseline.dataset[0].shape\n",
    "\n",
    "print(\"\")\n",
    "print(\"Baseline shape: \", baseline.dataset[1].shape)\n",
    "print(\"Test shape: \", test.dataset[1].shape)\n",
    "print(\"Prediction shape: \", predictions.shape)\n",
    "print(\"--- --- ---\")\n",
    "pred_auc, pred_f1 = ev_metrics.compute_auc(test.dataset[1], dataset.convert(predictions))\n",
    "base_auc, base_f1 = ev_metrics.compute_auc(test.dataset[1], baseline.dataset[1])\n",
    "print(\"Predictions mean AUC: \", pred_auc)\n",
    "print(\"Baseline mean AUC: \", base_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(constrained_layout=True, figsize=(5, 4))\n",
    "plt.plot(range(1, num_ts + 1), pred_auc, 'x-', c='tab:blue', label='prediction', ms=8)\n",
    "plt.plot(range(1, num_ts + 1), base_auc, 'o-', c='tab:green', label='baseline')\n",
    "plt.legend()\n",
    "plt.title('AUC on single timestep')\n",
    "plt.xlabel('Timestep')\n",
    "plt.xticks([0, 2, 4, 6, 8, 10])\n",
    "plt.ylabel('ROC AUC')\n",
    "name = 'auc' + str()\n",
    "plt.savefig('auc.eps', format='eps')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(constrained_layout=True, figsize=(5, 4))\n",
    "plt.plot(range(1, num_ts + 1), pred_f1, 'x-', c='tab:blue', label='prediction', ms=8)\n",
    "plt.plot(range(1, num_ts + 1), base_f1, 'o-', c='tab:green', label='baseline')\n",
    "plt.legend()\n",
    "plt.title('F1 on single timestep')\n",
    "plt.xlabel('Timestep')\n",
    "plt.xticks([0, 2, 4, 6, 8, 10])\n",
    "plt.ylabel('F1')\n",
    "name = 'auc' + str()\n",
    "plt.savefig('fscore.eps', format='eps')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Predictions mean AUC: \", pred_auc)\n",
    "print(\"Baseline mean AUC: \", base_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Predictions mean AUC: \", pred_f1)\n",
    "print(\"Baseline mean AUC: \", base_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Pred shape: \", predictions.shape)\n",
    "predictions_ = predictions[:, 88*0:88*1]\n",
    "print(predictions_.shape)\n",
    "print(test.dataset[0].shape, \"\\n\\n\\n\")\n",
    "test2 = test.dataset[0][:, 0, :]\n",
    "predictions2 = dataset.transpose(predictions_)\n",
    "predictions2 = dataset.convert(predictions2)\n",
    "# test = test[:, 0, :]\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 5))\n",
    "plot_piano_roll(dataset.transpose(test2), 21, 109, ax1, FS)\n",
    "ax1.set_title('Test')\n",
    "\n",
    "plot_piano_roll(predictions2, 21, 109, ax2, FS)\n",
    "ax2.set_title('Predictions')\n",
    "plt.show()\n",
    "print(\"Training time: \", (end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = dataset.DataGenerator(test_list, P / \"data\",  fs=FS, bl=0)\n",
    "test.build_dataset(\"test\", step=st, t_step=num_ts)\n",
    "baseline = dataset.DataGenerator(test_list, P / \"data\",  fs=FS, bl=1)\n",
    "baseline.build_dataset(\"test\", step=st, t_step=num_ts)\n",
    "baseline.dataset[0].shape\n",
    "base_auc, base_f1 = ev_metrics.compute_auc(test.dataset[1], baseline.dataset[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(constrained_layout=True, figsize=(5, 4))\n",
    "# plt.plot(range(1, num_ts + 1), pred_auc, 'x-', c='tab:blue', label='prediction', ms=8)\n",
    "plt.plot(range(1, num_ts + 1), base_auc, 'o-', c='tab:green', label='baseline')\n",
    "plt.legend()\n",
    "plt.title('AUC on single timestep')\n",
    "plt.xlabel('Timestep')\n",
    "# plt.xticks([0, 2, 4, 6, 8, 10,])\n",
    "plt.ylabel('ROC AUC')\n",
    "name = 'auc' + str()\n",
    "plt.savefig('auc.eps', format='eps')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
